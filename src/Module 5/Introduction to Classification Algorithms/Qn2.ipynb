{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Binary vs. Multi-Class Classification<br>\n",
    "\n",
    "Task 1:<br>\n",
    "Binary Classification: Predict if a website visitor will click a button (Click or No Click).<br>\n",
    "Use a web visitor interaction dataset.<br>\n",
    "Task: Implement binary classification for click prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79       104\n",
      "           1       0.77      0.80      0.79        96\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.79      0.79      0.79       200\n",
      "weighted avg       0.79      0.79      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a synthetic dataset representing website visitor interactions\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "# Features (example): time spent on site, number of pages visited, referral source (encoded as numeric)\n",
    "time_spent = np.random.normal(loc=60, scale=30, size=n_samples)  # seconds\n",
    "pages_visited = np.random.poisson(lam=5, size=n_samples)\n",
    "referral_source = np.random.choice([0, 1, 2], size=n_samples)  # 0=direct, 1=search, 2=ads\n",
    "\n",
    "# Target: click (1) or no click (0), synthetic logic: more time and pages -> more likely click\n",
    "click_prob = 1 / (1 + np.exp(-0.05*(time_spent - 50) + 0.3*(pages_visited - 3)))\n",
    "click = np.random.binomial(1, click_prob)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'time_spent': time_spent,\n",
    "    'pages_visited': pages_visited,\n",
    "    'referral_source': referral_source,\n",
    "    'click': click\n",
    "})\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['click'])\n",
    "y = df['click']\n",
    "\n",
    "# One-hot encode categorical feature (referral_source)\n",
    "X = pd.get_dummies(X, columns=['referral_source'], drop_first=True)\n",
    "\n",
    "# Split dataset (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2:<br>\n",
    "Multi-Class Classification: Recognize handwritten digits (0-9).<br>\n",
    "Use the MNIST dataset.<br>\n",
    "Task: Develop a model that correctly classifies each handwritten digit.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       0.93      0.93      0.93        46\n",
      "           2       1.00      1.00      1.00        44\n",
      "           3       1.00      1.00      1.00        46\n",
      "           4       0.98      1.00      0.99        45\n",
      "           5       1.00      0.98      0.99        46\n",
      "           6       1.00      0.98      0.99        45\n",
      "           7       0.98      1.00      0.99        45\n",
      "           8       0.91      0.93      0.92        43\n",
      "           9       0.98      0.96      0.97        45\n",
      "\n",
      "    accuracy                           0.98       450\n",
      "   macro avg       0.98      0.98      0.98       450\n",
      "weighted avg       0.98      0.98      0.98       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load MNIST digits dataset from sklearn (8x8 images of digits)\n",
    "digits = load_digits()\n",
    "\n",
    "X = digits.data  # Flattened pixel features (64 features)\n",
    "y = digits.target  # Digit labels 0-9\n",
    "\n",
    "# Split dataset (75% train, 25% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train logistic regression with multinomial option for multi-class\n",
    "model = LogisticRegression(max_iter=1000, multi_class='multinomial', solver='lbfgs', random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3:<br>\n",
    "Multi-Class Classification: Classify a flower species based on petal and sepal measurements.<br>\n",
    "Use the Iris dataset.<br>\n",
    "Task: Use features to classify into three species: Setosa, Versicolor, or Virginica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       0.90      0.90      0.90        10\n",
      "   virginica       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.93      0.93        30\n",
      "weighted avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # features: sepal length, sepal width, petal length, petal width\n",
    "y = iris.target  # species: 0=Setosa, 1=Versicolor, 2=Virginica\n",
    "\n",
    "# Split dataset (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train logistic regression for multi-class classification\n",
    "model = LogisticRegression(max_iter=200, multi_class='multinomial', solver='lbfgs', random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=iris.target_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
